{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook is a short summary of the ***ProxSkip*** optimization algorithm introduced in the following ***[paper](https://proceedings.mlr.press/v162/mishchenko22b.html)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem Statement\n",
    "The paper tackles the following class of problems: \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$$\n",
    "\n",
    "where $f: \\mathbb{R}^d: \\mathbb{R}$ is a smooth function and $\\psi: \\mathbb{R}^d: \\mathbb{R}$ is a proper closed convex regularizer\n",
    "\n",
    "The Proximal Gradient descent, also known as the forward-backward algorithm is the de-facto approach: \n",
    "\n",
    "$$ x_{t+1} = prox_{\\gamma_t \\psi}(x_t - \\gamma_t \\nabla f(x_t))$$\n",
    "\n",
    "where the $prox$ operator is defined as: \n",
    "\n",
    "$$ prox_{\\gamma \\psi}(x) = \\argmin_{y \\in \\mathbb{R}^d} [~\\frac{1}{2} \\| x - y \\| ^ 2 + \\psi(x)~]$$\n",
    "\n",
    "This approach (as well as the more recent method built on top of it) is suited for problems where the ***proximity operator*** is inexpensive while the bottleneck mainly lies in the gradient: $\\nabla f$.\n",
    "\n",
    "The authors of ***ProxSkip*** tackle a different sub-class of problems where the ***proximity operator*** is ***expensive*** while forward pass: $\\nabla f$ is computationally cheap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The relevance of the problem\n",
    "It is crucial to consider the relevance and usefulness of the problem tackled by the paper's authors.\n",
    "\n",
    "The success of Machine Learning is to a great extent due to the substantial increase in both computational power and generated data. Distributing the training accross multiple nodes presented itself as a very promising and attractive path to minimize the time requirements of the training process. Nevertheless, such directions has inherent computational issues: mainly the communication cost between different nodes which is a pillar of ***Federated Learning***. \n",
    "\n",
    "In distributed training, the prox operator requires calling the different nodes which as mentioned above computationally expensive. Therefore, the authors are tackling a problem rooted in both industry and academia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Contributions\n",
    "The paper introduces a new optimization method with a convergence rate \n",
    "$$O(k \\frac{1}{\\epsilon})$$ \n",
    "where $k =\\frac{L}{u}$ and a number of proxy operator rate (in expectation) \n",
    "$$O(\\sqrt{K} \\frac{1}{\\epsilon})$$ \n",
    "without any assumptions on the data unlike several recent proposed methods.\n",
    "\n",
    "The same convergence and proxy operator rates hold for both stochastic and distributed training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis\n",
    "This section describes a sketch of the proof of the convergence and proxy operator rates: \n",
    "\n",
    "### Known facts and assumptions:\n",
    "1. $f$ is convex and $\\psi$ is proper convex closed regularizer\n",
    "2. The assumption above implies that the problem has a unique solution denoted by $x^* = \\argmin_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$\n",
    "3. Two other important implications are the following: \n",
    "    * $\\| prox_f(x) − prox_f y \\| ^ 2 + \\|(x − prox_f (x)) − (y − prox_f (x)) \\|^2 \\leq \\|x - y \\| ^ 2$\n",
    "    * $\\forall \\gamma$, $x^*$ satisfies $ x = prox_{f_1} (x  - \\gamma \\cdot \\nabla f_2 (x))$\n",
    "\n",
    "Introducing a bit of notation : \n",
    "* $h^{*} = \\nabla f(x^*)$ \n",
    "* $P(.) = prox_{\\gamma ~ \\psi}(.)$\n",
    "* $x = \\hat{x}_{t+1} − \\frac{γ}{p} \\cdot h_t$\n",
    "* $y = x^{*} - \\frac{\\gamma}{p} h^{*}$\n",
    "\n",
    "1. First step let's rewrite the $x_{t+1}$ and $h_{t+1}$ in terms of $x_t$ and $h_t$:\n",
    "$\n",
    "x_{t + 1} = \n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "P(x) ~~  p \\\\\n",
    "\\hat{x}_{t+1} ~~ 1 - p\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "$\n",
    "h_{t + 1} = \n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "h_t + \\frac{p}{\\gamma} (P(x) - \\hat{x}_{t+1}) ~~ p \\\\\n",
    "h_t ~~ 1 - p\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "The main result is: \n",
    "\n",
    "$$\\mathbb{E}[\\Psi(t)] = (1 - \\xi)^{T} \\Psi_{0}$$\n",
    "where $\\Psi(t) = \\|x_t - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}[\\Psi(t + 1)] &= p (\\|P(x) - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t + \\frac{p}{\\gamma} (P(x) - \\hat{x}_{t + 1}) - h^{*} \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2) && \\text{this can be written as}\\\\\n",
    "\n",
    "\\mathbb{E}[\\Psi(t + 1)] &= p (\\|P(x) - P(y) \\| ^ 2 + \\|P(x) - x + y - P(y) \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2)  && \\text{algebric manipulation}\\\\\n",
    "\n",
    "\\mathbb{E}[\\Psi(t + 1)] &= p (\\|x - y \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2)  && \\text{applying firm nonexpansiveness}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "recalling the definitions:\n",
    "\n",
    "* $x = \\hat{x}_{t+1} − \\frac{γ}{p} \\cdot h_t$\n",
    "* $y = x^{*} - \\frac{\\gamma}{p} h^{*}$\n",
    "\n",
    "then:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq p (\\|x - y \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2) \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 - 2 \\cdot \\gamma <\\hat{x}_{t + 1} - x^{*}, h_t - h^{*}> + \\frac{\\gamma ^ 2}{ p ^ 2} + \\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 - 2 \\cdot \\gamma <\\hat{x}_{t + 1} - x^{*}, h_t - h^{*}> + \\gamma \\cdot \\|h_t - h^{*} \\| ^ 2 + (\\frac{\\gamma ^ 2}{ p ^ 2} - \\gamma)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot (1 - p^2)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using strong convexity and smoothness of $f$, we can estimate an upper bound for the first term\n",
    "\n",
    "\\begin{align*}\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 &= \\|x_{t} - x^{*} - \\gamma(\\nabla f(x_t) - \\nabla f(x^*)) \\| ^ 2\\\\\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 &= \\|x_{t} - x^{*}\\| ^ 2 + \\gamma ^ 2 \\cdot \\| \\nabla f(x_t) - \\nabla f(x^*) \\| ^ 2 - 2\\gamma <\\nabla f(x_t) - \\nabla f(x^*), x_t - x^{*}> \\\\\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 & \\leq (1 - \\gamma \\mu) \\|x_{t} - x^{*}\\| ^ 2 + \\gamma ^ 2 \\cdot \\| \\nabla f(x_t) - \\nabla f(x^*) \\| ^ 2 - 2\\gamma D_f(x_t, x^*) && \\text{using strong convexity} \\\\\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 & \\leq (1 - \\gamma \\mu) \\|x_{t} - x^{*}\\| ^ 2 - 2 \\gamma ^  \\cdot (2\\gamma D_f(x_t, x^*) - \\frac{\\gamma}{2} \\| \\nabla f(x_t) - \\nabla f(x^*) \\| ^ 2 )\\\\\n",
    "\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 & \\leq (1 - \\gamma \\mu) \\|x_{t} - x^{*}\\| ^ 2 && \\text{The last term is negative for $0 < \\gamma < \\frac{1}{L}$}\\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining both intermediate results, we reach the main result of the paper:\n",
    "\\begin{align}\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot (1 - p^2)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq (1 - \\mu \\gamma) \\|x_t - x^{*}\\|^2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot (1 - p^2)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq (1 - \\xi) (\\|x_t - x^{*}\\|^2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot \\| h_t - h^{*} \\| ^ 2) && \\text{$\\xi = \\min(\\gamma \\mu , p^2)$}\\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq (1 - \\xi) \\Psi(t)\\\\\n",
    "\\end{align}\n",
    "\n",
    "This equality proves the linear convergence rate of the ***ProxSkip*** method while proving that $h_t$ converges to $\\nabla f (x^*)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy operator rates\n",
    "Using the convergence rate, we can say that for $T \\geq \\max(\\frac{1}{\\mu \\gamma}, \\frac{1}{p^2}) \\log (\\frac{1}{\\epsilon})$, we have \n",
    "\n",
    "$$\\mathbb{E}[\\Psi(T)] \\leq \\epsilon \\Psi(t)$$\n",
    "\n",
    "Since the proxy operatory will be called $p \\cdot T$ (on average) after $T$ iterations we can say that for\n",
    "\n",
    "$$ p \\cdot \\max(\\frac{1}{\\mu \\gamma}, \\frac{1}{p^2}) \\log (\\frac{1}{\\epsilon}) =  \\max(\\frac{p}{\\mu \\gamma}, \\frac{1}{p}) \\log (\\frac{1}{\\epsilon})$$\n",
    "prox operator calls we have:\n",
    "\n",
    "$$\\mathbb{E}[\\Psi(T)] \\leq \\epsilon \\Psi(t)$$\n",
    "\n",
    "The next step is to minimize the term $\\max(\\frac{p}{\\mu \\gamma}, \\frac{1}{p})$ which reaches the minimum value for the maximum step size $\\gamma = \\frac{1}{L}$ and $\\frac{p}{\\mu \\gamma} = \\frac{1}{p}$ implying $p = \\frac{1}{\\sqrt{k}}$.\n",
    "\n",
    "Thus, for $\\gamma = \\frac{1}{L}$, $p = \\frac{1}{\\sqrt{k}}$, The proxy operator rate is:\n",
    "$$O(\\sqrt{K} \\frac{1}{\\epsilon})$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors apply standard techniques to prove similar rates for the case of the Stochastic and Federated Learning versions of the algorithm."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
