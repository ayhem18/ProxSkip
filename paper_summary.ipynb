{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook is a short summary of the ***ProxSkip*** optimization algorithm introduced in the following ***[paper](https://proceedings.mlr.press/v162/mishchenko22b.html)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem statement\n",
    "ProxSkip tackles the following class fo problems: \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$$\n",
    "\n",
    "where $f: \\mathbb{R}^d: \\mathbb{R}$ is a smooth, convex function and $\\psi: \\mathbb{R}^d: \\mathbb{R}$ is an expensive, non-smooth regularizer. \n",
    "\n",
    "Numerous applications can be represented in such setting: \n",
    "\n",
    "1. Signal Processing: Splitting a signal (a function) into a sum of functions with convex constraints: the constraints can be modeled as an indicator function across all sets [1](https://arxiv.org/pdf/0912.3522.pdf) \n",
    "2. Machine Learning: Decentralized / distributed training is crucial to train huge models. Consensus form is a mechanism to ensure that local solutions (in different devices) can be effectively leveraged to minimize the ***global objective*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prox Gradient Descent: The starting point\n",
    "Such class of problems is generally sovled with the Proximal Gradient Descent:\n",
    "\n",
    "$$ x_{t+1} = prox_{\\gamma_t \\psi}(x_t - \\gamma_t \\nabla f(x_t))$$\n",
    "\n",
    "where the $prox$ operator is defined as: \n",
    "\n",
    "$$ prox_{\\gamma \\psi}(x) = \\argmin_{y \\in \\mathbb{R}^d} [~\\frac{1}{2} \\| x - y \\| ^ 2 + \\gamma \\cdot \\psi(x)~]$$\n",
    "\n",
    "Even though the proximity operator presents itself as a sub optimization problem, closed formulas have been developed for most standard and popular regularizers: such as  $\\|x\\|_1$ , $\\|x\\|_2$ ... \n",
    "\n",
    "However, since $\\psi$ is generally non-smooth and not differentiable (at least not on its entire domain, take $\\|x\\|_1$ for example),the computation of the ***PROX OPERATOR*** can turn out quite computationally expensive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expensive Proxy Operators: \n",
    "## Inherently Computationally expensive\n",
    "\n",
    "The proximity operator bridges the gap between constrained and unconstrained optimization where the problem: \n",
    "\n",
    "$$ \n",
    "\\min_{x \\in \\mathbb{R}^d} f(x) \\\\\n",
    "x \\in X\n",
    "$$\n",
    "\n",
    "is formulized as: \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\psi(x) =\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "    0 && \\text{if $x \\in X$} \\\\\n",
    "    \\infty && \\text{if $x \\not\\in X$} \\\\\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "This operation can represent a difficult optimization problem for a several complex sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expensive Communication-wise\n",
    "The proximity operator emerges in decentralized training regime. Assuming $m$ devices, the global training objective is: \n",
    "\n",
    "\n",
    "original problem:=\n",
    "\n",
    "\n",
    "$$ \n",
    "\n",
    "f(x) = \\frac{1}{n} \\sum_{i = 1} ^ n f_i(x) \\\\\n",
    "$$\n",
    "\n",
    "We will model the problem as $f(X)$\n",
    "$$\n",
    "f(X) = f(x_1, x_2, ... x_n) = \\frac{1}{n} \\sum_{i = 1} ^ n f_i(x_i) \\\\\n",
    "$$\n",
    "\n",
    "but adding the constraint, $$x_1 = x_2, ..., = x_{n - 1} = x_n$$\n",
    "\n",
    "\n",
    "As you have probably guessed such constraint can be expressed in terms of a proxy operator:  \n",
    "\n",
    "$$\n",
    "\\psi_C(x_1, x_2, ..., x_{n - 1}, x_n) =\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "    0 && \\text{if $x_1 = x_2 = , ..., =  x_{n - 1} = x_n$} \\\\\n",
    "    \\infty && \\text{otherwise} \\\\\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theoretical solution for \n",
    "\n",
    "\n",
    "is the average of $x_i$ which is theoretically straightforward. However, in Federated Learning, such a simple operation would require $O(n)$ communincations which can be prohibitly expensive mainly in the modern settings ($n$ is quite large.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProxSkip: A provable solution:\n",
    "\n",
    "The concensus constraint is just a single example of several other expensive constraints due to communication constraints has been seeking better Gradient Descent methods with a communication rate lower than $$ O(\\kappa \\cdot \\frac{1}{\\epsilon})$$ with no additional assumptions on data similarity of stronger smoothness assumptions. \n",
    "\n",
    "where  $\\kappa = \\frac{L}{\\mu}$\n",
    "\n",
    "The authors of the paper introduce a version of the Prox Gradient Descent where the proximity operator is calculated $p$ times less frequently (on average) and ***Scaffnew*** an extension of this algorithm to distributed training settings without referring to any particular acceleration mechanisms.\n",
    "\n",
    "Scaffnew achieves Linear Convergence rate : $$O(\\kappa \\cdot \\log(\\frac{1}{\\epsilon}))$$\n",
    "and the theoretically optimal communication rate: \n",
    "\n",
    "$$O(\\sqrt{\\kappa} \\cdot \\log(\\frac{1}{\\epsilon}))$$ \n",
    "\n",
    "The authors extend vanilla ProxSkip to Stochastic ProxSkip and Decentralized version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Analysis: The magic Explained\n",
    "\n",
    "## Assumptions:\n",
    "1. $f$ is strongly convex with constant $\\mu$, smooth with constant $L$\n",
    "2. $\\psi$ is a proper, convex and closed regularizer. \n",
    "3. Firm non-expansiveness: The proxy operator is assumed to satisfy the following inequality for all $x,y \\in \\mathbb{R}^d$:\n",
    "\n",
    "    $$\n",
    "    \\| prox_{\\psi}(x) − prox_{\\psi} y \\| ^ 2 + \\|(x − prox_{\\psi} (x)) − (y − prox_{\\psi} (x)) \\|^2 \\leq \\|x - y \\| ^ 2\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intuition\n",
    "<p float=\"left\">\n",
    "  <img src=\"proximal_gd.png\" width=\"600\" />\n",
    "  <img src=\"proxskip.png\" width=\"600\" /> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProxSKip does not only differ with the Proximal Gradient Descent not only by skipping the Proximity operator but by adding a control mechanism, or as referred to in the paper **controle variate**. \n",
    "\n",
    "In general, the gradient of $f$ at $x^{*}$ is not necessarily $0$. Thus, Skipping the proximity operator without proper compensation would lead $x_t$ to drift from $x^{*}$.\n",
    "\n",
    "$$\n",
    "\\hat{x}_{ t + 1} = x_t - \\gamma (\\nabla f(x_t) - h_t) \\\\ \n",
    "$$\n",
    "\n",
    "Intuitively if we would like the algorithm to converge: \n",
    "\n",
    "$$ \n",
    "\\lim_{x_t \\rightarrow \\infty} = x^{*}\n",
    "$$\n",
    "\n",
    "Intuitively, $h_t$ should converge to $\\nabla f(x^*)$ as when $x_t$ converges to $x^{*}$, we would like the term after $\\gamma$ to converge to $0$. More formally, we would a Lyapounove function $\\psi$ in terms of $x_t, h_t, x^{*}, h^{*}$ that (in expectation) converges to $0$. The authors chose the following:   \n",
    "\n",
    "$$ \n",
    "\\psi_{t} = \\|x_t - x^{*} \\| ^ 2 + (\\frac{\\gamma}{p})^2 \\cdot  \\|h_t - h^{*} \\| ^ 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors prove that for any $t \\geq 1$, $~\\frac{1}{L} \\geq \\gamma > 0$, the inequality: \n",
    "\n",
    "$$ \\mathbb{E}[\\psi_t] \\leq (1 - \\xi) ^ T \\cdot \\psi_0 $$\n",
    "\n",
    "where $\\xi = \\min \\{\\gamma \\cdot \\mu , p^2\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Important Results:\n",
    "Under the assumptions listed above, convex analysis tells us that: \n",
    "\n",
    "1. There is a unique minimizer for the problem: $f + \\psi$\n",
    "\n",
    "2. Using the strong convexity of $f$, we have: \n",
    "\n",
    "\\begin{align}\n",
    "f(y) &\\geq f(x) + < \\nabla f(x), y - x> ~ + \\frac{\\mu}{2} \\cdot \\| x - y\\|^2 \\\\\n",
    "\\iff <\\nabla f(x), x - y> ~ &\\geq f(x) - f(y) + \\frac{\\mu}{2} \\cdot \\| x - y\\|^2\n",
    "\\end{align}\n",
    "\n",
    "3. Using the $L$ smoothness of $f$:\n",
    "\\begin{align}\n",
    "f(x) - f(y) - <\\nabla f(y), x - y> ~ \\geq \\frac{1}{2 \\cdot L} \\cdot \\| x - y\\|^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting Remark: \n",
    "Let's, as in the paper, denote $prox_{\\frac{\\gamma}{p}}(.)$ by $P(.)$. $P$ satisfies the following equation: \n",
    "\n",
    "$$ \n",
    "x^{*} = P(x^{*} - \\frac{\\gamma}{p} \\cdot h^{*})\n",
    "$$\n",
    "\n",
    "where $h^{*} = \\nabla f(x^{*})$ \n",
    "\n",
    "This is a powerful property of the proximity operator which can be proven as follows:\n",
    "\n",
    "\\begin{align}\n",
    "y &= \\argmin_{u \\in \\mathbb{R}^d} \\frac{1}{2} \\| u - x^{*} + \\alpha h^{*}\\|^2 + \\alpha \\cdot \\psi(u) \\\\\n",
    "\\iff 0 &\\in  \\delta ( \\frac{1}{2} \\| u - x^{*} + \\alpha h^{*}\\|^2 + \\alpha \\cdot \\psi(u)) \\\\\n",
    "\\iff 0 &\\in   u - x^{*} + \\alpha \\nabla(x^{*}) + \\alpha \\cdot \\delta \\psi(u) \\\\\n",
    "\\end{align}\n",
    "\n",
    "On the other hand: \n",
    "\\begin{align}\n",
    "x^{*} &= \\argmin_{u \\in \\mathbb{R}^d} f(x) + \\alpha \\cdot \\psi(x) \\\\\n",
    "\\iff 0 & \\in \\nabla f (x^{*})+ \\alpha \\cdot \\delta \\psi(x) \\\\\n",
    "\\iff 0 & \\in x^{*} + \\nabla f (x^{*})+  - x^{*} + \\alpha \\cdot \\delta \\psi(x)\n",
    "\\end{align}\n",
    "\n",
    "We can see that $x^{*}$ satisfies the equality of the sub-norm above. Thus:\n",
    "\n",
    "$$ \n",
    "x^{*} = P(x^{*} - \\frac{\\gamma}{p} \\cdot h^{*})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this identity, firm non-expansiveness, the authors an estimation of the expectation at $t$ completely without the Proximity operators: \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\Psi(t + 1)] = p (\\|\\hat{x}_{t+1} − \\frac{γ}{p} \\cdot h_t - (x^{*} - \\frac{\\gamma}{p} h^{*}) \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2)\n",
    "$$\n",
    "\n",
    "The proof is explained in details in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy operator rates\n",
    "Using the convergence rate, we can say that for $T \\geq \\max(\\frac{1}{\\mu \\gamma}, \\frac{1}{p^2}) \\log (\\frac{1}{\\epsilon})$, we have \n",
    "\n",
    "$$\\mathbb{E}[\\Psi(T)] \\leq \\epsilon \\Psi(t)$$\n",
    "\n",
    "Since the proxy operatory will be called $p \\cdot T$ (on average) after $T$ iterations we can say that for\n",
    "\n",
    "$$ p \\cdot \\max(\\frac{1}{\\mu \\gamma}, \\frac{1}{p^2}) \\log (\\frac{1}{\\epsilon}) =  \\max(\\frac{p}{\\mu \\gamma}, \\frac{1}{p}) \\log (\\frac{1}{\\epsilon})$$\n",
    "prox operator calls we have:\n",
    "\n",
    "$$\\mathbb{E}[\\Psi(T)] \\leq \\epsilon \\Psi(t)$$\n",
    "\n",
    "The next step is to minimize the term $\\max(\\frac{p}{\\mu \\gamma}, \\frac{1}{p})$ which reaches the minimum value for the maximum step size $\\gamma = \\frac{1}{L}$ and $\\frac{p}{\\mu \\gamma} = \\frac{1}{p}$ implying $p = \\frac{1}{\\sqrt{\\kappa}}$.\n",
    "\n",
    "Thus, for $\\gamma = \\frac{1}{L}$, $p = \\frac{1}{\\sqrt{k}}$, The proxy operator rate is:\n",
    "$$O(\\sqrt{\\kappa} \\frac{1}{\\epsilon})$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors apply standard techniques to prove similar rates for the case of the Stochastic and Federated Learning versions of the algorithm."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
