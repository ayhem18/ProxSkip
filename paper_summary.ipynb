{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook is a short summary of the ***ProxSkip*** optimization algorithm introduced in the following ***[paper](https://proceedings.mlr.press/v162/mishchenko22b.html)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem statement\n",
    "ProxSkip tackles the following class fo problems: \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$$\n",
    "\n",
    "where $f: \\mathbb{R}^d: \\mathbb{R}$ is a smooth, convex function and $\\psi: \\mathbb{R}^d: \\mathbb{R}$ is an expensive, non-smooth regularizer. \n",
    "\n",
    "Numerous applications can be represented in such setting: \n",
    "\n",
    "1. Signal Processing: Splitting a signal (a function) into a sum of functions with convex constraints: the constraints can be modeled as an indicator function across all sets [1](https://arxiv.org/pdf/0912.3522.pdf) \n",
    "2. Machine Learning: Decentralized / distributed training is crucial to train huge models. Consensus form is a mechanism to ensure that local solutions (in different devices) can be effectively leveraged to minimize the ***global objective*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prox Gradient Descent: The starting point\n",
    "Such class of problems is generally sovled with the Proximal Gradient Descent:\n",
    "\n",
    "$$ x_{t+1} = prox_{\\gamma_t \\psi}(x_t - \\gamma_t \\nabla f(x_t))$$\n",
    "\n",
    "where the $prox$ operator is defined as: \n",
    "\n",
    "$$ prox_{\\gamma \\psi}(x) = \\argmin_{y \\in \\mathbb{R}^d} [~\\frac{1}{2} \\| x - y \\| ^ 2 + \\gamma \\cdot \\psi(x)~]$$\n",
    "\n",
    "Even though the proximity operator presents itself as a sub optimization problem, closed formulas have been developed for most standard and popular regularizers: such as  $\\|x\\|_1$ , $\\|x\\|_2$ ... \n",
    "\n",
    "However, since $\\psi$ is generally non-smooth and not differentiable (at least not on its entire domain, take $\\|x\\|_1$ for example),the computation of the ***PROX OPERATOR*** can turn out quite computationally expensive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expensive Proxy Operators: \n",
    "## Inherently Computationally expensive\n",
    "\n",
    "The proximity operator bridges the gap between constrained and unconstrained optimization where the problem: \n",
    "\n",
    "$$ \n",
    "\\min_{x \\in \\mathbb{R}^d} f(x) \\\\\n",
    "x \\in X\n",
    "$$\n",
    "\n",
    "is formulized as: \n",
    "\n",
    "$$ \\min_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\psi(x) =\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "    0 && \\text{if $x \\in X$} \\\\\n",
    "    \\infty && \\text{if $x \\not\\in X$} \\\\\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "This operation can represent a difficult optimization problem for a several complex sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expensive Communication-wise\n",
    "The proximity operator emerges in decentralized training regime. Assuming $m$ devices, the global training objective is: \n",
    "\n",
    "$$ \n",
    "f(x) = \\frac{1}{n} \\sum_{i = 1} ^ n f_i(x)\n",
    "$$\n",
    "\n",
    "As explained in [2](https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf) (chapter 5), the key to computational efficiency is to break the problem formulation into a sum of seperable problems: each problem can be then solved independently. However, the global objective should not be comprised and hence the addition of the consensus constraint: \n",
    "\n",
    "$$\n",
    "\\psi_C(x_1, x_2, ..., x_{n - 1}, x_n) =\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "    0 && \\text{if $x_1 = x_2, ..., x_{n - 1} = x_n$} \\\\\n",
    "    \\infty && \\text{otherwise} \\\\\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "ensuring that local minimization (thus, computational gain) leads to the global minimum.\n",
    "\n",
    "The solution to the proximity operator: \n",
    "$$\n",
    "prox_{\\gamma \\psi_C}(x_1, x_2, ..., x_n) = \\argmin_{y_1, y_2, .. y_n \\in \\mathbb{R}^d} [~\\frac{1}{2} \\sum_{i}^{n}\\| x_i - y_i \\| ^ 2 + \\gamma \\cdot \\psi_C(y_i)~]\n",
    "$$\n",
    "\n",
    "is the average of $x_i$ which is theoretically straightforward. However, in Federated Learning, such a simple operation would require $O(n)$ communincations which can be prohibitly expensive mainly in the modern settings ($n$ is quite large.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProxSkip: A provable solution:\n",
    "\n",
    "The concensus constraint is just a single example of several other expensive constraints due to communication constraints. The federated Learning community has been seeking better local Gradient algorithms with lower communication rate that $ O(k \\cdot \\frac{1}{\\epsilon})$ with no additional assumptions on data \n",
    "similarity of stronger smoothness assumptions. \n",
    "\n",
    "The authors of the paper introduce a version of the Prox Gradient Descent where the proximity operator is calculated $p$ times less frequently (on average) and ***Scaffnew*** an extension of this algorithm to distributed training settings without referring to any particular acceleration mechanisms.\n",
    "\n",
    "Scaffnew achieves Linear Convergence rate : $$O(K \\cdot \\frac{1}{\\epsilon})$$\n",
    "and the theoretically optimal communication rate: \n",
    "$$O(\\sqrt{K} \\cdot \\frac{1}{\\epsilon})$$ \n",
    "\n",
    "The authors extend vanilla ProxSkip to Stochastic ProxSkip and Decentralized version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Analysis: The magic Explained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis\n",
    "This section describes a sketch of the proof of the convergence and proxy operator rates: \n",
    "\n",
    "### Known facts and assumptions:\n",
    "1. $f$ is convex and $\\psi$ is proper convex closed regularizer\n",
    "2. The assumption above implies that the problem has a unique solution denoted by $x^* = \\argmin_{x \\in \\mathbb{R}^d} f(x) + \\psi(x)$\n",
    "3. Two other important implications are the following: \n",
    "    * $\\| prox_f(x) − prox_f y \\| ^ 2 + \\|(x − prox_f (x)) − (y − prox_f (x)) \\|^2 \\leq \\|x - y \\| ^ 2$\n",
    "    * $\\forall \\gamma$, $x^*$ satisfies $ x = prox_{f_1} (x  - \\gamma \\cdot \\nabla f_2 (x))$\n",
    "\n",
    "Introducing a bit of notation : \n",
    "* $h^{*} = \\nabla f(x^*)$ \n",
    "* $P(.) = prox_{\\gamma ~ \\psi}(.)$\n",
    "* $x = \\hat{x}_{t+1} − \\frac{γ}{p} \\cdot h_t$\n",
    "* $y = x^{*} - \\frac{\\gamma}{p} h^{*}$\n",
    "\n",
    "1. First step let's rewrite the $x_{t+1}$ and $h_{t+1}$ in terms of $x_t$ and $h_t$:\n",
    "$\n",
    "x_{t + 1} = \n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "P(x) ~~  p \\\\\n",
    "\\hat{x}_{t+1} ~~ 1 - p\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "$\n",
    "h_{t + 1} = \n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "h_t + \\frac{p}{\\gamma} (P(x) - \\hat{x}_{t+1}) ~~ p \\\\\n",
    "h_t ~~ 1 - p\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "The main result is: \n",
    "\n",
    "$$\\mathbb{E}[\\Psi(t)] = (1 - \\xi)^{T} \\Psi_{0}$$\n",
    "where $\\Psi(t) = \\|x_t - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\mathbb{E}[\\Psi(t + 1)] &= p (\\|P(x) - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t + \\frac{p}{\\gamma} (P(x) - \\hat{x}_{t + 1}) - h^{*} \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2) && \\text{this can be written as}\\\\\n",
    "\n",
    "\\mathbb{E}[\\Psi(t + 1)] &= p (\\|P(x) - P(y) \\| ^ 2 + \\|P(x) - x + y - P(y) \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2)  && \\text{algebric manipulation}\\\\\n",
    "\n",
    "\\mathbb{E}[\\Psi(t + 1)] &= p (\\|x - y \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2)  && \\text{applying firm nonexpansiveness}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "recalling the definitions:\n",
    "\n",
    "* $x = \\hat{x}_{t+1} − \\frac{γ}{p} \\cdot h_t$\n",
    "* $y = x^{*} - \\frac{\\gamma}{p} h^{*}$\n",
    "\n",
    "then:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq p (\\|x - y \\| ^ 2) + (1 - p) \\cdot (\\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 + \\frac{\\gamma ^ 2}{p^2} \\|h_t - h^{*} \\| ^ 2) \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 - 2 \\cdot \\gamma <\\hat{x}_{t + 1} - x^{*}, h_t - h^{*}> + \\frac{\\gamma ^ 2}{ p ^ 2} + \\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|\\hat{x}_{t + 1} - x^{*} \\| ^ 2 - 2 \\cdot \\gamma <\\hat{x}_{t + 1} - x^{*}, h_t - h^{*}> + \\gamma \\cdot \\|h_t - h^{*} \\| ^ 2 + (\\frac{\\gamma ^ 2}{ p ^ 2} - \\gamma)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot (1 - p^2)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using strong convexity and smoothness of $f$, we can estimate an upper bound for the first term\n",
    "\n",
    "\\begin{align*}\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 &= \\|x_{t} - x^{*} - \\gamma(\\nabla f(x_t) - \\nabla f(x^*)) \\| ^ 2\\\\\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 &= \\|x_{t} - x^{*}\\| ^ 2 + \\gamma ^ 2 \\cdot \\| \\nabla f(x_t) - \\nabla f(x^*) \\| ^ 2 - 2\\gamma <\\nabla f(x_t) - \\nabla f(x^*), x_t - x^{*}> \\\\\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 & \\leq (1 - \\gamma \\mu) \\|x_{t} - x^{*}\\| ^ 2 + \\gamma ^ 2 \\cdot \\| \\nabla f(x_t) - \\nabla f(x^*) \\| ^ 2 - 2\\gamma D_f(x_t, x^*) && \\text{using strong convexity} \\\\\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 & \\leq (1 - \\gamma \\mu) \\|x_{t} - x^{*}\\| ^ 2 - 2 \\gamma ^  \\cdot (2\\gamma D_f(x_t, x^*) - \\frac{\\gamma}{2} \\| \\nabla f(x_t) - \\nabla f(x^*) \\| ^ 2 )\\\\\n",
    "\n",
    "\\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 & \\leq (1 - \\gamma \\mu) \\|x_{t} - x^{*}\\| ^ 2 && \\text{The last term is negative for $0 < \\gamma < \\frac{1}{L}$}\\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining both intermediate results, we reach the main result of the paper:\n",
    "\\begin{align}\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq \\|(\\hat{x}_{t + 1} - h_t) - (x^{*} - h^{*}) \\| ^ 2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot (1 - p^2)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq (1 - \\mu \\gamma) \\|x_t - x^{*}\\|^2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot (1 - p^2)\\| h_t - h^{*} \\| ^ 2 \\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq (1 - \\xi) (\\|x_t - x^{*}\\|^2 + \\frac{\\gamma ^ 2}{ p ^ 2} \\cdot \\| h_t - h^{*} \\| ^ 2) && \\text{$\\xi = \\min(\\gamma \\mu , p^2)$}\\\\\n",
    "\\mathbb{E}[\\Psi(t + 1)] &\\leq (1 - \\xi) \\Psi(t)\\\\\n",
    "\\end{align}\n",
    "\n",
    "This equality proves the linear convergence rate of the ***ProxSkip*** method while proving that $h_t$ converges to $\\nabla f (x^*)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy operator rates\n",
    "Using the convergence rate, we can say that for $T \\geq \\max(\\frac{1}{\\mu \\gamma}, \\frac{1}{p^2}) \\log (\\frac{1}{\\epsilon})$, we have \n",
    "\n",
    "$$\\mathbb{E}[\\Psi(T)] \\leq \\epsilon \\Psi(t)$$\n",
    "\n",
    "Since the proxy operatory will be called $p \\cdot T$ (on average) after $T$ iterations we can say that for\n",
    "\n",
    "$$ p \\cdot \\max(\\frac{1}{\\mu \\gamma}, \\frac{1}{p^2}) \\log (\\frac{1}{\\epsilon}) =  \\max(\\frac{p}{\\mu \\gamma}, \\frac{1}{p}) \\log (\\frac{1}{\\epsilon})$$\n",
    "prox operator calls we have:\n",
    "\n",
    "$$\\mathbb{E}[\\Psi(T)] \\leq \\epsilon \\Psi(t)$$\n",
    "\n",
    "The next step is to minimize the term $\\max(\\frac{p}{\\mu \\gamma}, \\frac{1}{p})$ which reaches the minimum value for the maximum step size $\\gamma = \\frac{1}{L}$ and $\\frac{p}{\\mu \\gamma} = \\frac{1}{p}$ implying $p = \\frac{1}{\\sqrt{k}}$.\n",
    "\n",
    "Thus, for $\\gamma = \\frac{1}{L}$, $p = \\frac{1}{\\sqrt{k}}$, The proxy operator rate is:\n",
    "$$O(\\sqrt{K} \\frac{1}{\\epsilon})$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors apply standard techniques to prove similar rates for the case of the Stochastic and Federated Learning versions of the algorithm."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
