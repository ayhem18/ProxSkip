{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook, we try to replicate 2 of the paper experiments: optimizing the logistic regression loss with\n",
    "\n",
    "1. Stochastic Local Gradient Descent VS Stochastic Scaffnew\n",
    "\n",
    "2. Local Gradient Descent (Deterministic) Vs Scaffnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data splitting \n",
    "Please take a look at the 'exp_setup' and 'optimization_utilities' files for the definition of most functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download an crucial package first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/konstmish/opt_methods.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from typing import Sequence, Union, List, Tuple\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(69)\n",
    "random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp_setup import split_into_batches, download_dataset\n",
    "# download the data\n",
    "DATA, LABELS = download_dataset()\n",
    "\n",
    "# the number of devices used across the notebook\n",
    "NUM_DEVICES = 16\n",
    "DEVICES_DATA, DEVICES_LABELS = split_into_batches(DATA, y=LABELS, even_split=False, batch_size=int(math.ceil(DATA.shape[0] /NUM_DEVICES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the minimum number of samples in each device \n",
    "MIN_DEVICE_SIZE = min([d_data.shape[0] for d_data in DEVICES_DATA])\n",
    "# set the batch size\n",
    "BATCH_SIZE = MIN_DEVICE_SIZE // 4\n",
    "print(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTIMAT THE SMOOTHNESS CONSTANT\n",
    "from exp_setup import L_estimation\n",
    "PROBLEM_L = L_estimation(DEVICES_DATA, DEVICES_LABELS)\n",
    "# SET THE REGULARIZATION PARAMETERS AS IN THE PAPER\n",
    "PROBLEM_LAMBDA = PROBLEM_L * 10 ** -4\n",
    "print(PROBLEM_L, PROBLEM_LAMBDA)\n",
    "# set the LEARNING RATE: \n",
    "LEARNING_RATE = 1 / (PROBLEM_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from exp_setup import lr_loss, stochastic_lr_gradient, stochastic_lr_loss, lr_gradient\n",
    "\n",
    "DETERMINISTIC_FUNTION =partial(lr_loss, lam=PROBLEM_LAMBDA)\n",
    "DETERMINISTIC_GRADIENT_FUNCTION = partial(lr_gradient, lam=PROBLEM_LAMBDA)\n",
    "STOCHASTIC_FUNCTION = partial(stochastic_lr_loss, lam=PROBLEM_LAMBDA, batch_size=BATCH_SIZE)\n",
    "STOCHASTIC_GRADIENT_FUNCTION = partial(stochastic_lr_gradient, lam=PROBLEM_LAMBDA, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimization_utilities as opt\n",
    "# create the set up: x_0 and seed\n",
    "def set_up(seed: int = 69) -> np.ndarray:\n",
    "        # changing the seed mainly changes the starting point\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    w_0 = np.random.randn(DATA.shape[1], 1)\n",
    "    return w_0\n",
    "\n",
    "# find the minimum value of the function\n",
    "TRUE_MIN = opt.find_x_true(DATA, LABELS, lam=PROBLEM_LAMBDA) \n",
    "print(TRUE_MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Local Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_iterations(criterions: List[float],\n",
    "                    start_index: int = 0, \n",
    "                    end_index: int = -1,\n",
    "                    plot_label: str = None,\n",
    "                    x_label: str = None,\n",
    "                    y_label: str = None,\n",
    "                    show:bool = True,\n",
    "                    ):\n",
    "    \n",
    "    end_index = (end_index + len(criterions)) % len(criterions)\n",
    "\n",
    "    if plot_label is None:\n",
    "        plt.plot(list(range(start_index, end_index)), criterions[start_index:end_index])\n",
    "    else:\n",
    "        plt.plot(list(range(start_index, end_index)), criterions[start_index:end_index], label=str(plot_label))\n",
    "    \n",
    "\n",
    "    plt.xlabel('iteration' if x_label is None else x_label)\n",
    "    plt.ylabel('criterion (log_{10} scale)' if x_label is None else y_label)\n",
    "    \n",
    "    if show:\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K =  10 ** 5\n",
    "NUM_LOCAL_STEPS = 200\n",
    "COMMUNICATION_ROUNDS = K // NUM_LOCAL_STEPS\n",
    "CRITERION = lambda x: np.mean([lr_loss(d_data, d_label, x, PROBLEM_LAMBDA) for d_data, d_label in zip(DEVICES_DATA, DEVICES_LABELS)]) - TRUE_MIN\n",
    "X0 = set_up()\n",
    "\n",
    "INITIAL_VALUE = CRITERION(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimization_utilities as opt\n",
    "import importlib\n",
    "importlib.reload(opt)\n",
    "\n",
    "local_gd_xpoints, local_gd_criterions = opt.localGD(\n",
    "                                                num_local_steps=NUM_LOCAL_STEPS,\n",
    "                                                device_data=DEVICES_DATA, \n",
    "                                                device_labels=DEVICES_LABELS,\n",
    "                                                function=DETERMINISTIC_FUNTION,\n",
    "                                                gradient_function=STOCHASTIC_GRADIENT_FUNCTION,            \n",
    "                                                x_0=X0,\n",
    "                                                mode=CRITERION, \n",
    "                                                gamma_k=lambda _ :1 / LEARNING_RATE, \n",
    "                                                K=K\n",
    "                                                )\n",
    "local_gd_criterions = [INITIAL_VALUE] + local_gd_criterions\n",
    "# convert the criterion value1s to log 'scale'\n",
    "local_gd_log_criterions = [np.log10(c) for c in local_gd_criterions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plot_iterations(criterions=local_gd_log_criterions, \n",
    "                x_label='communication rounds', \n",
    "                y_label='f(x) - f(*): log 10', \n",
    "                show=False)\n",
    "plt.yticks(np.linspace(np.min(local_gd_log_criterions), np.max(local_gd_log_criterions), num=20))\n",
    "plt.title(f\"Stochastic Local GD with {NUM_DEVICES} devices and {NUM_LOCAL_STEPS} local steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic ProxSkip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the optimial prox skip probability\n",
    "PROX_SKIP_PROBABILITY = np.sqrt(PROBLEM_LAMBDA / LEARNING_RATE)\n",
    "# add some extra \n",
    "PROX_SKIP_K =  K ** 2\n",
    "print(PROX_SKIP_PROBABILITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optimization_utilities as opt\n",
    "import importlib\n",
    "importlib.reload(opt)\n",
    "prox_xpoints, prox_criterions = opt.proxSkipFL(\n",
    "            devices_data=DEVICES_DATA, \n",
    "            devices_labels=DEVICES_LABELS,\n",
    "            function=DETERMINISTIC_FUNTION,\n",
    "            gradient_function=STOCHASTIC_GRADIENT_FUNCTION,\n",
    "            skip_probability=PROX_SKIP_PROBABILITY, \n",
    "            communication_rounds=COMMUNICATION_ROUNDS,\n",
    "            x_0=set_up(), \n",
    "            max_iterations=PROX_SKIP_K, \n",
    "            gamma_k=lambda _ : 1 / LEARNING_RATE,\n",
    "            mode=CRITERION,\n",
    "            report_by_prox=50,\n",
    "            )\n",
    "\n",
    "# add the initial value \n",
    "prox_criterions = [INITIAL_VALUE] + prox_criterions\n",
    "prox_log_criterions = [np.log10(max(c, 10 ** -8)) for c in prox_criterions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_gd_log_criterions = [np.log10(INITIAL_VALUE)] + local_gd_log_criterions\n",
    "prox_log_criterions = [np.log10(INITIAL_VALUE)] + prox_log_criterions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plot_iterations(criterions=local_gd_log_criterions, \n",
    "                x_label='communication rounds', \n",
    "                y_label='f(x) - f(*): log 10', \n",
    "                plot_label='local GD',\n",
    "                show=False)\n",
    "\n",
    "plot_iterations(criterions=prox_log_criterions, \n",
    "                x_label='communication rounds', \n",
    "                y_label='f(x) - f(*): log 10', \n",
    "                plot_label='Prox Skip',\n",
    "                show=False)\n",
    "\n",
    "plt.yticks(np.linspace(\n",
    "                        start=min(np.min(local_gd_log_criterions), np.min(prox_log_criterions)), \n",
    "                        stop=max(np.max(local_gd_log_criterions), np.max(prox_log_criterions)),num=20\n",
    "                                 ))\n",
    "plt.legend()\n",
    "plt.title(f'S Prox Skip, p:{round(PROX_SKIP_PROBABILITY, 5)}, SLGD: {NUM_DEVICES} devices, {NUM_LOCAL_STEPS} local steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinsistic Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K =  10 ** 5\n",
    "NUM_LOCAL_STEPS = 30\n",
    "COMMUNICATION_ROUNDS = K // NUM_LOCAL_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = set_up()\n",
    "INITIAL_VALUE = CRITERION(X0)\n",
    "INITIAL_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_gd_xpoints, local_gd_criterions = opt.localGD(\n",
    "                                                num_local_steps=NUM_LOCAL_STEPS,\n",
    "                                                device_data=DEVICES_DATA, \n",
    "                                                device_labels=DEVICES_LABELS,\n",
    "                                                function=DETERMINISTIC_FUNTION,\n",
    "                                                gradient_function=DETERMINISTIC_GRADIENT_FUNCTION,            \n",
    "                                                x_0=X0,\n",
    "                                                mode=CRITERION, \n",
    "                                                gamma_k=lambda _ :1 / 4 * PROBLEM_L, \n",
    "                                                K=K\n",
    "                                                )\n",
    "local_gd_criterions = [INITIAL_VALUE] + local_gd_criterions \n",
    "local_gd_log_criterions = [np.log10(c) for c in local_gd_criterions] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROX_SKIP_PROBABILITY = np.sqrt(PROBLEM_LAMBDA / (4 * PROBLEM_L))\n",
    "PROX_SKIP_K =  K ** 2\n",
    "PROX_SKIP_PROBABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_xpoints, prox_criterions = opt.proxSkipFL(\n",
    "            devices_data=DEVICES_DATA, \n",
    "            devices_labels=DEVICES_LABELS,\n",
    "            function=DETERMINISTIC_FUNTION,\n",
    "            gradient_function=DETERMINISTIC_GRADIENT_FUNCTION,\n",
    "            skip_probability=PROX_SKIP_PROBABILITY, \n",
    "            communication_rounds=COMMUNICATION_ROUNDS,\n",
    "            x_0=set_up(), \n",
    "            max_iterations=PROX_SKIP_K, \n",
    "            gamma_k=lambda _ : 1 / 4 * PROBLEM_L,\n",
    "            mode=CRITERION,\n",
    "            report_by_prox=50\n",
    "            )\n",
    "\n",
    "prox_criterions = [INITIAL_VALUE] + prox_criterions\n",
    "prox_log_criterions = [np.log10(c) for c in prox_criterions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plot_iterations(criterions=local_gd_log_criterions, \n",
    "                x_label='communication rounds', \n",
    "                y_label='f(x) - f(*): log 10', \n",
    "                plot_label='local GD',\n",
    "                show=False)\n",
    "\n",
    "plot_iterations(criterions=prox_log_criterions, \n",
    "                x_label='communication rounds', \n",
    "                y_label='f(x) - f(*): log 10', \n",
    "                plot_label='Prox Skip',\n",
    "                show=False)\n",
    "\n",
    "plt.yticks(np.linspace(\n",
    "                        start=min(np.min(local_gd_log_criterions), np.min(prox_log_criterions)), \n",
    "                        stop=max(np.max(local_gd_log_criterions), np.max(prox_log_criterions)),num=20\n",
    "                                 ))\n",
    "plt.legend()\n",
    "plt.title(f'Prox Skip, p:{round(PROX_SKIP_PROBABILITY, 5)}, LGD: {NUM_DEVICES} devices, {NUM_LOCAL_STEPS} local steps')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
