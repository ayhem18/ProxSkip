{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: requests in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: filelock in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.27.4.1)\n",
      "Requirement already satisfied: lit in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-18\n",
    "\n",
    "This experiment will train a ResNet-18 model on the CIFAR-10 dataset using the Prox Skip algorithm (Stochastic setting) and Local SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The first thing to do is to pull and prepare CIFAR-10 dataset for the model to be trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proxskip.types import Vector\n",
    "from proxskip.data import DataLoader\n",
    "\n",
    "class StochasticCIFARBatchLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    def get(self) -> tuple[Vector, Vector]:\n",
    "        random_batch = torch.randint(0, len(self.dataset), (self.batch_size,))\n",
    "        images = self.dataset.data[random_batch]\n",
    "        images = torch.stack([self.transforms(image) for image in images])\n",
    "        \n",
    "        return images, torch.tensor([self.dataset.targets[int(i)] for i in random_batch], dtype=torch.long)\n",
    "    \n",
    "    def total_size(self) -> int:\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_data(self, left: int, size: int) -> tuple[Vector, Vector]:\n",
    "        images = self.dataset.data[left:left+size]\n",
    "        images = torch.stack([self.transforms(image) for image in images])\n",
    "        targets = torch.tensor(self.dataset.targets[left:(left+size)], dtype=torch.long)\n",
    "        return images, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proxskip.types import Vector\n",
    "from proxskip.model import Model\n",
    "\n",
    "class CIFARModel(Model):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(512, 10)\n",
    "        \n",
    "        self.resnet = self.resnet.to(self.device)\n",
    "        \n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self._params = [key for key, _ in self.resnet.named_parameters()]\n",
    "        self._params.sort()\n",
    "        \n",
    "        \n",
    "    def forward(self, x: Vector) -> Vector:\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = x.to(self.device).to(torch.float32)\n",
    "        else:\n",
    "            x = torch.tensor(x, device=self.device)\n",
    "        return self.resnet(x).detach().cpu().numpy()\n",
    "    \n",
    "    def backward(self, x: Vector, upstream: Vector) -> Vector:\n",
    "        for param in self.resnet.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        y = self.resnet(torch.tensor(x, device=self.device))\n",
    "        y.backward(torch.tensor(upstream, device=self.device))\n",
    "            \n",
    "        # Concatenate all gradients into a single vector \n",
    "        return torch.cat([self.resnet.get_parameter(p).grad.flatten() for p in self._params]).detach().cpu().numpy()\n",
    "    \n",
    "    def update(self, params: Vector) -> None:\n",
    "        # The params vector contains the gradients for each parameter\n",
    "        # flattened into a single vector. We need to unflatten it\n",
    "        # and update the parameters accordingly.\n",
    "        shift = 0\n",
    "        for p in self._params:\n",
    "            param = self.resnet.get_parameter(p)\n",
    "            size = param.grad.numel()\n",
    "            param = torch.tensor(\n",
    "                params[shift:shift+size].reshape(param.grad.shape), \n",
    "                device=self.device,\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "            shift += size\n",
    "            \n",
    "            self.resnet.get_parameter(p).data = param\n",
    "            \n",
    "    def params(self) -> Vector:\n",
    "        return torch.cat([self.resnet.get_parameter(p).flatten() for p in self._params]).detach().cpu().numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proxskip.model import Model\n",
    "from proxskip.types import Vector\n",
    "from proxskip.loss import LossFunction\n",
    "\n",
    "class CrossEntropyLoss(LossFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def loss(self, m: Model, X: Vector, y: Vector) -> Vector:\n",
    "        return self.loss_fn(\n",
    "            torch.tensor(m.forward(X), device=self.device), \n",
    "            torch.tensor(y, device=self.device)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def upstream_gradient(self, m: Model, X: Vector, y: Vector) -> Vector:\n",
    "        y_pred = m.forward(torch.tensor(X, device=self.device))\n",
    "        y_pred = torch.tensor(y_pred, device=self.device)\n",
    "        y_pred.requires_grad = True\n",
    "        \n",
    "        loss = self.loss_fn(y_pred, torch.tensor(y, device=self.device))\n",
    "        loss.backward()\n",
    "        \n",
    "        return y_pred.grad.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from proxskip.consensus import ConsesusProx\n",
    "from proxskip.optimizer import StochasticProxSkip\n",
    "\n",
    "models = [CIFARModel()]\n",
    "loss_fn = CrossEntropyLoss()\n",
    "dataloaders = [StochasticCIFARBatchLoader(trainset, batch_size=32)]\n",
    "num_iterations = 1000\n",
    "communication_rounds = 1000\n",
    "\n",
    "\n",
    "ps_optimizer = StochasticProxSkip(\n",
    "    models=models,\n",
    "    dataloaders=dataloaders,\n",
    "    loss=loss_fn,\n",
    "    prox=ConsesusProx(),\n",
    "    num_iterations=num_iterations ** 2, # to have `comminication_rounds` of loss values\n",
    "    learning_rate=1E-4,\n",
    "    p=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders[0].total_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/teexone/miniconda3/envs/uni/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_865791/852636446.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = m.forward(torch.tensor(X, device=self.device))\n",
      "/tmp/ipykernel_865791/852636446.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = self.loss_fn(y_pred, torch.tensor(y, device=self.device))\n",
      "/tmp/ipykernel_865791/2051475764.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = self.resnet(torch.tensor(x, device=self.device))\n",
      "/tmp/ipykernel_865791/852636446.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y, device=self.device)\n",
      "loss=2.4370:   2%|▏         | 15/1000 [20:01<21:55:10, 80.11s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     on_prox \u001b[39m=\u001b[39m ps_optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m on_prox \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m c \u001b[39m==\u001b[39m communication_rounds:\n\u001b[1;32m      8\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/uni/opt/ProxSkip/proxskip/optimizer.py:390\u001b[0m, in \u001b[0;36mStochasticProxSkip.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    389\u001b[0m X, y \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39mget_data(i, \u001b[39m32\u001b[39m)\n\u001b[0;32m--> 390\u001b[0m local_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_\u001b[39m.\u001b[39;49mloss(uni_model, X, y)\n\u001b[1;32m    391\u001b[0m n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    392\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mCrossEntropyLoss.loss\u001b[0;34m(self, m, X, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, m: Model, X: Vector, y: Vector) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Vector:\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(\n\u001b[0;32m---> 13\u001b[0m         torch\u001b[39m.\u001b[39mtensor(m\u001b[39m.\u001b[39;49mforward(X), device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), \n\u001b[1;32m     14\u001b[0m         torch\u001b[39m.\u001b[39mtensor(y, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     15\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m, in \u001b[0;36mCIFARModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(x, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 26\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresnet(x)\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "progress = trange(communication_rounds)\n",
    "c = 0\n",
    "while True:\n",
    "    on_prox = ps_optimizer.step()\n",
    "    if on_prox is None or c == communication_rounds:\n",
    "        break\n",
    "    if on_prox:\n",
    "        progress.set_description(f\"loss={ps_optimizer._step['loss'][-1].item():.4f}\")\n",
    "        progress.update(1)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
